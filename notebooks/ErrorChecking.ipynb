{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "75634c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.forecasting.compose import make_reduction, TransformedTargetForecaster\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('../data/car_parts_final.csv', parse_dates = ['Date'])\n",
    "df.set_index(['Series', 'Date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "3e4e98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds   = pd.read_csv('../results/linear_regression_differenced_20230826-182504/ensemble_preds.csv')\n",
    "results = pd.read_csv('../results/linear_regression_differenced_20230826-182504/metric_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "ec1ec982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Values'] = df.groupby(level = 0)['Values'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0389ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = range(1, min(10, int(np.ceil(51 / 10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "cf43a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in lags:\n",
    "    df[f'lag_{lag}'] = df.groupby(level = 0)['Values'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7b3eda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = TransformedTargetForecaster([\n",
    "    Differencer(lags = 1, na_handling = 'drop_na') *\n",
    "    make_reduction(LinearRegression(), window_length = 1, strategy = 'recursive')\n",
    "])\n",
    "\n",
    "mod2 = make_reduction(LinearRegression(), window_length = 1, strategy = 'recursive')\n",
    "mod3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "6613c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data to use\n",
    "fake             = pd.DataFrame(np.random.normal(0, 0.25, size = 25), columns = ['Vals'])\n",
    "fake['prev']     = fake['Vals'].shift()\n",
    "fake['diff']     = fake['Vals'].diff()\n",
    "fake['prevdiff'] = fake['diff'].shift()\n",
    "fake.index       = pd.date_range(start = '2000-01-01', periods = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7b924822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22407836]\n",
      "-0.033275071520778896\n"
     ]
    }
   ],
   "source": [
    "# linear regression fitted on previous values\n",
    "print(LinearRegression().fit(fake[['prev']][1:], fake['Vals'][1:]).coef_)\n",
    "print(LinearRegression().fit(fake[['prev']][1:], fake['Vals'][1:]).intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "883e40e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': LinearRegression(),\n",
       " 'transformers': None,\n",
       " 'window_length': 1,\n",
       " 'estimator__coef': array([-0.22407836]),\n",
       " 'estimator__intercept': -0.033275071520778896,\n",
       " 'estimator__n_features_in': 1,\n",
       " 'estimator__rank': 1,\n",
       " 'estimator__singular': array([0.9969091])}"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to make_reduction -- it works\n",
    "mod2.fit(fake['Vals'])\n",
    "mod2.get_fitted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "270af2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forecaster': TransformedTargetForecaster(steps=[Differencer(na_handling='drop_na'),\n",
       "                                    RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                         window_length=1)]),\n",
       " 'steps': [('TransformedTargetForecaster',\n",
       "   TransformedTargetForecaster(steps=[Differencer(na_handling='drop_na'),\n",
       "                                      RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                           window_length=1)]))],\n",
       " 'transformers_post': [],\n",
       " 'transformers_pre': [],\n",
       " 'TransformedTargetForecaster': TransformedTargetForecaster(steps=[Differencer(na_handling='drop_na'),\n",
       "                                    RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                         window_length=1)]),\n",
       " 'TransformedTargetForecaster__forecaster': RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                      window_length=1),\n",
       " 'TransformedTargetForecaster__steps': [('Differencer',\n",
       "   Differencer(na_handling='drop_na')),\n",
       "  ('RecursiveTabularRegressionForecaster',\n",
       "   RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                        window_length=1))],\n",
       " 'TransformedTargetForecaster__transformers_post': [],\n",
       " 'TransformedTargetForecaster__transformers_pre': [('Differencer',\n",
       "   Differencer(na_handling='drop_na'))],\n",
       " 'TransformedTargetForecaster__Differencer': Differencer(na_handling='drop_na'),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster': RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                      window_length=1),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator': LinearRegression(),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__transformers': None,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__window_length': 1,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__coef': array([-0.66826683]),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__intercept': -0.034432605285480575,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__n_features_in': 1,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__rank': 1,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__singular': array([1.55460695])}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now compare to model pipeline w/ differencer and see results\n",
    "mod1.fit(fake['Vals'])\n",
    "mod1.get_fitted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6d3f0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66826683]\n",
      "-0.034432605285480575\n"
     ]
    }
   ],
   "source": [
    "# coefficients for model fit w/ Linear Regression -- And it works\n",
    "print(mod3.fit(fake.dropna()[['prevdiff']], fake.dropna()['diff']).coef_)\n",
    "print(mod3.fit(fake.dropna()[['prevdiff']], fake.dropna()['diff']).intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "29b413b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-26   -0.266702\n",
       "2000-01-27   -0.218325\n",
       "2000-01-28   -0.285086\n",
       "2000-01-29   -0.274904\n",
       "2000-01-30   -0.316141\n",
       "2000-01-31   -0.323017\n",
       "2000-02-01   -0.352854\n",
       "2000-02-02   -0.367347\n",
       "Freq: D, Name: Vals, dtype: float64"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now make a prediction -- is this the problem?\n",
    "mod1.predict(fh = [1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "ace464a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forecaster': TransformedTargetForecaster(steps=[Differencer(na_handling='drop_na'),\n",
       "                                    RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                         window_length=1)]),\n",
       " 'steps': [('TransformedTargetForecaster',\n",
       "   TransformedTargetForecaster(steps=[Differencer(na_handling='drop_na'),\n",
       "                                      RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                           window_length=1)]))],\n",
       " 'transformers_post': [],\n",
       " 'transformers_pre': [],\n",
       " 'TransformedTargetForecaster': TransformedTargetForecaster(steps=[Differencer(na_handling='drop_na'),\n",
       "                                    RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                         window_length=1)]),\n",
       " 'TransformedTargetForecaster__forecaster': RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                      window_length=1),\n",
       " 'TransformedTargetForecaster__steps': [('Differencer',\n",
       "   Differencer(na_handling='drop_na')),\n",
       "  ('RecursiveTabularRegressionForecaster',\n",
       "   RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                        window_length=1))],\n",
       " 'TransformedTargetForecaster__transformers_post': [],\n",
       " 'TransformedTargetForecaster__transformers_pre': [('Differencer',\n",
       "   Differencer(na_handling='drop_na'))],\n",
       " 'TransformedTargetForecaster__Differencer': Differencer(na_handling='drop_na'),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster': RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                      window_length=1),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator': LinearRegression(),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__transformers': None,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__window_length': 1,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__coef': array([-0.72990323]),\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__intercept': -0.02154210268340424,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__n_features_in': 1,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__rank': 1,\n",
       " 'TransformedTargetForecaster__RecursiveTabularRegressionForecaster__estimator__singular': array([1.46923544])}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work with larger values -- begin to coincide\n",
    "# now compare to model pipeline w/ differencer and see results\n",
    "mod1.fit(fake['Vals'][:21])\n",
    "mod1.get_fitted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "186ed0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.72990323]\n",
      "-0.02154210268340424\n"
     ]
    }
   ],
   "source": [
    "# linear regression model\n",
    "# coefficients for model fit w/ Linear Regression -- And it works\n",
    "print(mod3.fit(fake.dropna()[['prevdiff']][:19], fake.dropna()['diff'][:19]).coef_)\n",
    "print(mod3.fit(fake.dropna()[['prevdiff']][:19], fake.dropna()['diff'][:19]).intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e8732cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-22    0.012265\n",
       "Freq: D, Name: Vals, dtype: float64"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for next couple of values for mod1 -- DON'T MATCH!!\n",
    "mod1.predict(fh = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c827ec9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0207449 , -0.12659116, -0.02266725])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual value for 2000 - 01 - 21\n",
    "mod3.predict(fake[['prevdiff']].iloc[19:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "5bcb40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem is that out of sample forecasted values don't match, presumably because \n",
    "# it's using last value in the known time series?  not ideal for our usecases\n",
    "# maybe better to spin up our own functions -- and GET READY TO FINISH!\n",
    "# will look at evaluate function for now\n",
    "# sample evaluate result set\n",
    "splitter = ExpandingWindowSplitter(step_length=1, fh=[1], initial_window=20)\n",
    "results  = evaluate(mod1, \n",
    "                    y = fake['Vals'], \n",
    "                    cv = splitter, \n",
    "                    strategy = 'refit', \n",
    "                    return_data = True, \n",
    "                    error_score = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "574ef7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66826683]\n",
      "-0.034432605285480575\n"
     ]
    }
   ],
   "source": [
    "print(mod3.fit(fake.dropna()[['prevdiff']], fake.dropna()['diff']).coef_)\n",
    "print(mod3.fit(fake.dropna()[['prevdiff']], fake.dropna()['diff']).intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "19d9a7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3.fit(fake.dropna()[['prevdiff']][:18], fake.dropna()[['diff']][:18]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "232aa2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13513173]])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3.predict(fake.dropna()[['prevdiff']].iloc[18].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f61f1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample evaluate result set\n",
    "splitter = ExpandingWindowSplitter(step_length=1, fh=[1], initial_window=20)\n",
    "results  = evaluate(mod1, \n",
    "                    y = fake['Vals'], \n",
    "                    cv = splitter, \n",
    "                    strategy = 'refit', \n",
    "                    return_data = True, \n",
    "                    error_score = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "e7949eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample[['PrevValue']].dropna()\n",
    "y = sample['Values'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "78492855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Diff']     = sample['Values'].diff()\n",
    "sample['PrevDiff'] = sample['Diff'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "8e032a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now:  write function to fit a model on a series, and optionally fit it to a hierarchical time series\n",
    "def fit_model_on_data(model, y: pd.Series, X = None, start_idx: int = 25, model_args: dict = {}) -> pd.DataFrame:\n",
    "    \"\"\"Function to fit model on a singe time series of data & increment it w/ a walk forward validation step\"\"\"\n",
    "    \n",
    "    final_results = []\n",
    "    \n",
    "    m = y.shape[0]\n",
    "        \n",
    "    for s in range(start_idx, m):\n",
    "\n",
    "        y_temp = y.iloc[:s]\n",
    "            \n",
    "        if X is not None:\n",
    "            X_temp = X.iloc[:s]\n",
    "            model.fit(X_temp, y_temp, **model_args)\n",
    "            \n",
    "        else:\n",
    "            model.fit(y, **model_args)\n",
    "            \n",
    "        y_true = y.iloc[s]\n",
    "        \n",
    "        if X is not None:\n",
    "            y_pred = model.predict(X.iloc[s].to_frame())[0]\n",
    "        \n",
    "        else:\n",
    "            # TO DO:  Add in appropriate one step ahead forecast for next prediction\n",
    "            pass\n",
    "            \n",
    "        final_results.append({\n",
    "            'y_pred': y_pred,\n",
    "            'Date': X.iloc[s].name\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "6c5b0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample.dropna()[['PrevDiff']]\n",
    "y = sample.dropna()['Diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "5dba185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.466667</td>\n",
       "      <td>2000-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>2000-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.476744</td>\n",
       "      <td>2001-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.616438</td>\n",
       "      <td>2001-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2002-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2002-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2002-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred       Date\n",
       "0   0.000000 2000-04-01\n",
       "1   0.000000 2000-05-01\n",
       "2   0.000000 2000-06-01\n",
       "3   0.000000 2000-07-01\n",
       "4   0.000000 2000-08-01\n",
       "5  -0.466667 2000-09-01\n",
       "6   0.695652 2000-10-01\n",
       "7   0.000000 2000-11-01\n",
       "8   0.000000 2000-12-01\n",
       "9   0.000000 2001-01-01\n",
       "10  0.000000 2001-02-01\n",
       "11  0.000000 2001-03-01\n",
       "12  0.000000 2001-04-01\n",
       "13  0.000000 2001-05-01\n",
       "14  0.000000 2001-06-01\n",
       "15  0.000000 2001-07-01\n",
       "16  0.000000 2001-08-01\n",
       "17  0.000000 2001-09-01\n",
       "18 -0.476744 2001-10-01\n",
       "19  0.616438 2001-11-01\n",
       "20  0.000000 2001-12-01\n",
       "21  0.000000 2002-01-01\n",
       "22  0.000000 2002-02-01\n",
       "23  0.000000 2002-03-01"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model_on_data(LinearRegression(), X = sample.dropna()[['PrevDiff']], y =  sample.dropna()['Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "ef6a0d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 {color: black;background-color: white;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 pre{padding: 0;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-toggleable {background-color: white;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-estimator:hover {background-color: #d4ebff;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-item {z-index: 1;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-parallel-item:only-child::after {width: 0;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-e30884c2-393d-4448-8a9e-eba9aa5631f0 div.sk-text-repr-fallback {display: none;}</style><div id='sk-e30884c2-393d-4448-8a9e-eba9aa5631f0' class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TransformedTargetForecaster(steps=[TransformedTargetForecaster(steps=[Differencer(),\n",
       "                                                                      RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                                                           window_length=1)])])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class='sk-label-container'><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('9da70352-594c-41dd-8ea4-497488ce9f99') type=\"checkbox\" ><label for=UUID('9da70352-594c-41dd-8ea4-497488ce9f99') class='sk-toggleable__label sk-toggleable__label-arrow'>TransformedTargetForecaster</label><div class=\"sk-toggleable__content\"><pre>TransformedTargetForecaster(steps=[TransformedTargetForecaster(steps=[Differencer(),\n",
       "                                                                      RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                                                           window_length=1)])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('94005c59-b9a5-4631-9e43-fa062db17833') type=\"checkbox\" ><label for=UUID('94005c59-b9a5-4631-9e43-fa062db17833') class='sk-toggleable__label sk-toggleable__label-arrow'>Differencer</label><div class=\"sk-toggleable__content\"><pre>Differencer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('10df016a-f9fd-4eb5-a372-9e0c14a72710') type=\"checkbox\" ><label for=UUID('10df016a-f9fd-4eb5-a372-9e0c14a72710') class='sk-toggleable__label sk-toggleable__label-arrow'>LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "TransformedTargetForecaster(steps=[TransformedTargetForecaster(steps=[Differencer(),\n",
       "                                                                      RecursiveTabularRegressionForecaster(estimator=LinearRegression(),\n",
       "                                                                                                           window_length=1)])])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fake = pd.DataFrame(np.random.normal(0, 1, size = (100)))\n",
    "y_fake.index = pd.date_range(start = '2000-01-01', periods = 100)\n",
    "\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "fh = ForecastingHorizon([1, 2])\n",
    "\n",
    "model = TransformedTargetForecaster([\n",
    "    Differencer(lags = 1) *\n",
    "    make_reduction(LinearRegression(), window_length = 1, strategy = 'recursive')\n",
    "])\n",
    "\n",
    "model.fit(y_fake, fh = fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "b0c36692",
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "a0fc8e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[493], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;241m.23\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.18\u001b[39m]))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/base/_base.py:404\u001b[0m, in \u001b[0;36mBaseForecaster.predict\u001b[0;34m(self, fh, X)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_vectorized:\n\u001b[0;32m--> 404\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(fh\u001b[38;5;241m=\u001b[39mfh, X\u001b[38;5;241m=\u001b[39mX_inner)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/compose/_pipeline.py:1002\u001b[0m, in \u001b[0;36mTransformedTargetForecaster._predict\u001b[0;34m(self, fh, X)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, fh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    988\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forecast time series at future horizon.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03m        Point predictions\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1002\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecaster_\u001b[38;5;241m.\u001b[39mpredict(fh\u001b[38;5;241m=\u001b[39mfh, X\u001b[38;5;241m=\u001b[39mX)\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# inverse transform y_pred\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inverse_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_pre_, y_pred, X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/base/_base.py:404\u001b[0m, in \u001b[0;36mBaseForecaster.predict\u001b[0;34m(self, fh, X)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_vectorized:\n\u001b[0;32m--> 404\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(fh\u001b[38;5;241m=\u001b[39mfh, X\u001b[38;5;241m=\u001b[39mX_inner)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/compose/_pipeline.py:1002\u001b[0m, in \u001b[0;36mTransformedTargetForecaster._predict\u001b[0;34m(self, fh, X)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, fh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    988\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forecast time series at future horizon.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03m        Point predictions\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1002\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecaster_\u001b[38;5;241m.\u001b[39mpredict(fh\u001b[38;5;241m=\u001b[39mfh, X\u001b[38;5;241m=\u001b[39mX)\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# inverse transform y_pred\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inverse_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_pre_, y_pred, X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/base/_base.py:404\u001b[0m, in \u001b[0;36mBaseForecaster.predict\u001b[0;34m(self, fh, X)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_vectorized:\n\u001b[0;32m--> 404\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(fh\u001b[38;5;241m=\u001b[39mfh, X\u001b[38;5;241m=\u001b[39mX_inner)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/base/_sktime.py:30\u001b[0m, in \u001b[0;36m_BaseWindowForecaster._predict\u001b[0;34m(self, fh, X)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# all values are out-of-sample\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fh\u001b[38;5;241m.\u001b[39mis_all_out_of_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcutoff):\n\u001b[0;32m---> 30\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_fixed_cutoff(\n\u001b[1;32m     31\u001b[0m         fh\u001b[38;5;241m.\u001b[39mto_out_of_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcutoff), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# all values are in-sample\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fh\u001b[38;5;241m.\u001b[39mis_all_in_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcutoff):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/base/_sktime.py:74\u001b[0m, in \u001b[0;36m_BaseWindowForecaster._predict_fixed_cutoff\u001b[0;34m(self, fh, X, return_pred_int, alpha)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make single-step or multi-step fixed cutoff predictions.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03my_pred = pd.Series or pd.DataFrame\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# assert all(fh > 0)\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_last_window(\n\u001b[1;32m     75\u001b[0m     fh, X, return_pred_int\u001b[38;5;241m=\u001b[39mreturn_pred_int, alpha\u001b[38;5;241m=\u001b[39malpha\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_pred, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_pred, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sktime/forecasting/compose/_reduce.py:904\u001b[0m, in \u001b[0;36m_RecursiveReducer._predict_last_window\u001b[0;34m(self, fh, X, return_pred_int, alpha)\u001b[0m\n\u001b[1;32m    902\u001b[0m last[:, \u001b[38;5;241m0\u001b[39m, :window_length] \u001b[38;5;241m=\u001b[39m y_last\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 904\u001b[0m     last[:, \u001b[38;5;241m1\u001b[39m:, :window_length] \u001b[38;5;241m=\u001b[39m X_last\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    905\u001b[0m     last[:, \u001b[38;5;241m1\u001b[39m:, window_length:] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;241m-\u001b[39m(last\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m window_length) :, :\n\u001b[1;32m    907\u001b[0m     ]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    909\u001b[0m \u001b[38;5;66;03m# Recursively generate predictions by iterating over forecasting horizon.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "model.predict(X = pd.Series([.23, -.18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a946b",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "9f2fdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lookback_preds_for_series(model, \n",
    "                         y: pd.Series, \n",
    "                         X = None, \n",
    "                         start_idx: int = 25,\n",
    "                         model_args: dict = {}): \n",
    "    \"\"\"Build lookback predictions for Data\"\"\"\n",
    "    \n",
    "    max_window = min(10, int(np.ceil(len(y) / 10)))\n",
    "    \n",
    "    # check that index is a time stamp\n",
    "    if not np.issubdtype(sample.index.dtype, np.datetime64):\n",
    "        raise ValueError(\"Please make sure index column is a datetime\")\n",
    "        \n",
    "    if X is not None and len(y) != len(X):\n",
    "        raise ValueError(\"X & y are not the same shape\")\n",
    "    \n",
    "    \n",
    "    results           = pd.DataFrame()\n",
    "    results['y_true'] = y\n",
    "    results['Date']   = X.index\n",
    "    \n",
    "    for i in range(1, max_window):\n",
    "        print(i)\n",
    "        \n",
    "        lag_cols = [col for col in X.columns if \n",
    "                    int(col.split('_')[1]) <= i and col != 'Values']\n",
    "                        \n",
    "        X_temp   = X[lag_cols]\n",
    "        \n",
    "        # to remove null values from training data\n",
    "        idx = X_temp.notnull().all(axis = 1).values    \n",
    "\n",
    "        \n",
    "        preds = fit_model_on_data(model, \n",
    "                                     y = y.loc[idx], \n",
    "                                     X = X_temp.loc[idx], \n",
    "                                     start_idx  = start_idx,\n",
    "                                     model_args = model_args)\n",
    "        \n",
    "        print(preds.head())\n",
    "        results[f'y_pred_lag_{i}'] = preds['y_pred']\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "0fce3565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "   y_pred       Date\n",
      "0     0.0 2000-04-01\n",
      "1     0.0 2000-05-01\n",
      "2     0.0 2000-06-01\n",
      "3     0.0 2000-07-01\n",
      "4     0.0 2000-08-01\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but LinearRegression is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[454], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m build_lookback_preds_for_series(LinearRegression(), X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:], y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValues\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[453], line 34\u001b[0m, in \u001b[0;36mbuild_lookback_preds_for_series\u001b[0;34m(model, y, X, start_idx, model_args)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# to remove null values from training data\u001b[39;00m\n\u001b[1;32m     31\u001b[0m idx \u001b[38;5;241m=\u001b[39m X_temp\u001b[38;5;241m.\u001b[39mnotnull()\u001b[38;5;241m.\u001b[39mall(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues    \n\u001b[0;32m---> 34\u001b[0m preds \u001b[38;5;241m=\u001b[39m fit_model_on_data(model, \n\u001b[1;32m     35\u001b[0m                              y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mloc[idx], \n\u001b[1;32m     36\u001b[0m                              X \u001b[38;5;241m=\u001b[39m X_temp\u001b[38;5;241m.\u001b[39mloc[idx], \n\u001b[1;32m     37\u001b[0m                              start_idx  \u001b[38;5;241m=\u001b[39m start_idx,\n\u001b[1;32m     38\u001b[0m                              model_args \u001b[38;5;241m=\u001b[39m model_args)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(preds\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     41\u001b[0m results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred_lag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[429], line 23\u001b[0m, in \u001b[0;36mfit_model_on_data\u001b[0;34m(model, y, X, start_idx, model_args)\u001b[0m\n\u001b[1;32m     20\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[s]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[s]\u001b[38;5;241m.\u001b[39mto_frame())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# TO DO:  Add in appropriate one step ahead forecast for next prediction\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sklearn/linear_model/_base.py:354\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sklearn/linear_model/_base.py:337\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    335\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 337\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/time_series_ensembles/lib/python3.11/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but LinearRegression is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "build_lookback_preds_for_series(LinearRegression(), X = df.loc['T1'].iloc[:, 1:], y = df.loc['T1']['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb988ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
